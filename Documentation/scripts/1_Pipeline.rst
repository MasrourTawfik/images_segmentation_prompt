Pipeline
=============



.. _transformer_architecture:

1. Transformer Architecture Explained
-------------------------------------

.. figure:: /Documentation/images/arch1.png
   :width: 400
   :align: center
   :alt: Alternative Text


Le Transformer est une architecture révolutionnaire dans le domaine du traitement du langage naturel. Dans ce contexte, nous allons expliquer les différents aspects de cette architecture.

    * *Introduction (Attention is All You Need)*


       <https://arxiv.org/pdf/1706.03762.pdf>


      Cette introduction met en lumière les bases du Transformer, telles que décrites dans le papier "Attention is All You Need".

    * *Tokenization*

      La tokenization est le processus de conversion du texte en jetons, les unités de base sur lesquelles le modèle opère.

    * *Embedding*

      L'embedding transforme les jetons en vecteurs denses, qui représentent numériquement les mots.

    * *Positional encoding*

      L'encodage de position ajoute des informations sur l'ordre des mots dans la séquence.

    * *Transformer block*

      Le bloc Transformer est la pièce maîtresse de cette architecture, comprenant des couches d'attention et des réseaux de neurones entièrement connectés.

    * *Softmax*

      Softmax est une fonction d'activation utilisée pour calculer les scores de probabilité sur la sortie du modèle.

.. _visual_transformer:

2. Visual Transformer (ViT)
----------------------------

.. figure:: /Documentation/images/ViT.png
    :width: 400
    :align: center
    :alt: Alternative Text

<https://arxiv.org/pdf/2010.11929v2.pdf>


Expliquer le fonctionnement et l'utilisation du Visual Transformer.

.. _detection_transformer(DeTR):

3. Detection Transformer
-------------------------

.. figure:: /Documentation/images/detr.jpg
   :width: 400
   :align: center
   :alt: Alternative Text 


Expliquer le fonctionnement et l'utilisation du Detection Transformer(DeTR).
