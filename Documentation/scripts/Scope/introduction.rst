Project Introduction.
====================

1. introduction
-----------------



.. figure:: /Documentation/images/intro.jpg
   :width: 700
   :align: center
   :alt: Alternative text for the image

.. raw:: html

    <p style="text-align: justify;"><span style="color:#000080;">

    This project aims to build a bridge (a connection) between users' text request and object detection inside an image.

   </span></p>
    <p style="text-align: justify;"><i>

    - <span style="color:blue;"> First input:</span><span style="color:#000080;"> Users' text request (query or prompt) about an object;

    </i></span></p>

    <p style="text-align: justify;"><i>

    - <span style="color:blue;"> Second input : </span><span style="color:#000080;"> The image;

    </i></span></p>

    <p style="text-align: justify;"><i>

    - <span style="color:blue;">Output : </span><span style="color:#000080;">The requested object, filtred and highlightedÂ (segmented).
    </i></span></p>
    &#10003;<span style="color:blue;">For example: </span>
    <p style="text-align: justify;"><span style="color:#000080;"><i>
    the user has an image of people playing in the park, and wants to filter out dogs in the picture.
    </i></span></p>
    <p style="text-align: justify;"><span style="color:#000080;"><i>
    in order to do so, the user inserts the picture and writes this query: "highlight dogs in the picture"

    </i></span></p>
    <p style="text-align: justify;"><span style="color:#000080;"><i> 

    The output would be a processed images where dogs are highlighted
    </i></span></p>

> How were we able to do that ?





