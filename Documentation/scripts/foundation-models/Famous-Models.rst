Famous Models
===============

.. raw:: html

    <p><span style="color:white;">'</p></span>


.. figure:: /Documentation/images/foundation-models/grounding-DINO/1.jpg
   :width: 700
   :align: center
   :alt: Alternative text for the image

DINO
------

.. raw:: html

    <p><span style="color:white;">'</p></span>


.. figure:: /Documentation/images/foundation-models/grounding-DINO/1.jpg
   :width: 700
   :align: center
   :alt: Alternative text for the image


.. raw:: html

    <p><span style="color:white;">'</p></span>

    <p style="text-align: justify;"><span style="color:#000080;"><i>


    As of March 2023, there is a new SOTA zero-shot object detection model - Grounding DINO. In this post, we will talk about the advantages of Grounding DINO, analyze the model architecture, and provide real prompt examples. 
   </i></span></p>

    <p><span style="color:white;">'</p></span>
    
1. Introduction
_________________________

.. raw:: html

    <p><span style="color:white;">'</p></span>

    <p style="text-align: justify;"><span style="color:#000080;"><i>

    Most object detection models are trained to identify a narrow predetermined collection of classes. The main problem with this is the lack of flexibility. Every time you want to expand or change the set of recognizable objects, you have to collect data, label it, and train the model again. This — of course — is  time-consuming and expensive.
   </i></span></p>

    <p style="text-align: justify;"><span style="color:#000080;"><i>

    Zero-shot detectors want to break this status quo by making it possible to detect new objects without re-training a model. All you have to do is change the prompt and the model will detect the objects you describe.
   </i></span></p>

    <p style="text-align: justify;"><span style="color:#000080;"><i>

    Below we see two images visualizing predictions made with</span><span style="color:red;"><strong> Grounding DINO</span></strong><span style="color:#000080;"> — the new SOTA zero-shot object detection model.
   </i></span></p>
    <p style="text-align: justify;"><span style="color:#000080;"><i>

    In the case of the images below, we asked the model to identify the class <strong>" '</span><span style="color:red;">piano</span><span style="color:#000080;">', '</span><span style="color:red;">guitar</span><span style="color:#000080;">','</span><span style="color:red;">phone</span><span style="color:#000080;">','</span><span style="color:red;">hat</span><span style="color:#000080;">' " </strong> - a class belonging to the COCO dataset. The model successfully detected all objects of this class without any issues.
   </i></span></p>

    <p><span style="color:white;">'</p></span>

   <strong> text prompt :</strong>['piano', 'guitar','phone','hat'] 


.. figure:: /Documentation/images/foundation-models/grounding-DINO/2.jpg
   :width: 700
   :align: center
   :alt: Alternative text for the image

.. raw:: html

    <p><span style="color:white;">'</p></span>

.. figure:: /Documentation/images/foundation-models/grounding-DINO/3.jpg
   :width: 700
   :align: center
   :alt: Alternative text for the image

.. raw:: html

    <p><span style="color:white;">'</p></span>


.. figure:: /Documentation/images/foundation-models/grounding-DINO/4.jpg
   :width: 700
   :align: center
   :alt: Alternative text for the image

.. raw:: html

    <p><span style="color:white;">'</p></span>


Segment Anyting Model
-------------------------